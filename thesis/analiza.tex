\chapter{Przegląd literatury}

\section{Analiza wybranych rozwiązań literaturowych z dziedziny rozpoznawania akordów muzycznych za
pomocą sieci neuronowych}

% początek (humphrey)
\paragraph{Pierwszą} próbę rozpoznawania akordów muzycznych za pomocą sieci neuronowych podjęli Eric
J. Humphrey i Juan P. Bello w 2012 roku \cite{humphrey_rethinking_2012}. Opisali oni jak za pomocą
splotowej sieci neuronowej, stosowanej wcześniej głównie w rozpoznawaniu obrazów, można rozpoznawać
akordy muzyczne. Ich pomysł zapoczątkował całą serię badań innych ludzi zajmujących się ACR (ang.
Audio Chord Recognition), stanowiącego jedno z podstawowych zadań z dziedziny MIR (ang. Music
Information Retrieval). Zaproponowane przez nich rozwiązanie jest stosunkowo proste, dzisiaj
natomiast już zdecydowanie wymagające usprawnień. Wynika to z faktu, że faktyczny rozwój uczenia
głębokiego (ang. Deep Learning) rozpoczął się właśnie w roku 2012 i od tego czasu powstało całe
mnóstwo metod pozwalających osiągnąć dokładniejsze wyniki mniejszym kosztem obliczeniowym.

% opis prac Korzeniowskiego
\paragraph{Jedną} z najobszerniejszych serii prac dotyczących rozpoznawania akordów muzycznych z
wykorzystaniem sieci neuronowych wykonali Korzeniowski i Widmer. Na przestrzeni kilku lat
przeprowadzili szereg badań i wydali sześć arytkułów związanych z tym tematem. Artykuły te wynikają
kolejno jedne z drugich i nawzajem się uzupełniają. W pierwszym z nich
\cite{korzeniowski_feature_2016} autorzy proponują użycie perceptronu wielowarstwowego do ekstrakcji
cech dźwięku (ang. chroma feature) w miejsce wcześniej stosowanych deterministycznych, znacznie
mniej skomplikowanych algorytmów ekstrakcji cech. Tak powstała reprezentacja jest ich zdaniem
znacznie lepsza i może zostać wykorzystana do dalszej klasyfikacji akordów, lub w zupełnie innym
celu. Dodatkowo pomysł ten jest motywowany założeniem, że to właśnie ekstrakcja cech z surowych
danych gra kluczową rolę w jakości klasyfikacji akordów - jest znacznie ważniejsza od późniejszego
rozpoznawania konkretnego akordu i detekcji całej sekwnecji. W kolejnej pracy
\cite{korzeniowski_feature_2016} autorzy wykorzystują tym razem splotową sieć neuronową w połączeniu
z CRF (ang. Conditional Random Fields) aby stworzyć kompletny algorytm rozpoznający akordy.
Rozwiązania te stanowią punkt odniesienia dla wielu kolejnych prac (\cite{ohanlon_fifthnet_2021},
\cite{park_bi-directional_2019}), szczególnie sieć splotowa daje bardzo konkurencyjne wyniki.

W dalszym toku badań autorzy skupiają się na możliwości usprawnienia wcześniejszych rozwiązań
poprzez wykorzystanie modeli językowych i powiązania między zadaniem detekcji sekwencji akordów do
zadania detekcji i zrozumienia sekwencji słów w języku naturalnym. Najpierw udowadniają, że złożone
modele językowe (sieci rekurencyjne) nie sprawdzą się dobrze, jeśli będą stosowane na poziomie
pojedynczych ramek czasowych, a nie pojedynczych wystąpień akordów
\cite{korzeniowski_futility_2017}. W takiej sytuacji lepiej sprawdzają się znacznie prostsze modele
jak HMM (ang. Hidden Markov Model), które w praktyce jedynie "wygładzają" sekwencję akordów. W
kolejnych badaniach \cite{korzeniowski_large-scale_2018} wykazują, że modele stosowane do
przetwarzania języka naturalnego (ang. Natural Language Processing - NLP) mają duży potencjał i
potrafią skutecznie modelować zależności w sekwencjach akordów muzycznych (np. przewidywać cykle),
co pozwala usprawnić ogólną jakość klasyfikacji akordów. Autorzy opisują w końcu model
probabilistyczny, pozwalający połączyć model akustyczny (rozpoznający akordy w danej chwili czasu) z
modelem językowym (dekodującym całą sekwencję pojedynczych akordów), implementują go i
przeprowadzają szereg eksperymentów pozwalających potwierdzić, że tak zastosowane złożone modele
językowe usprawniają jakość klasyfikacji akordów \cite{korzeniowski_improved_2018}.

O ile opisane powyżej prace stanowią bardzo istotny wkład w dziedzinę badań nad zadaniem ACR (ang.
Audio Chord Recognition) i porządkują wiele aspektów tego zagadnienia (jak kwestia wykorzystania
modeli językowych) to w obecnej chwili są już raczej przestarzałe. Spostrzeżenia i wnioski zawarte w
tych pracach pozostają w większości aktualne, jednakże nie ma sensu stosowanie wykorzystywanych
wtedy architektur sieci neuronowych, ze względu na możliwość wykorzystania nowszych modeli, znacznie
dokładniejszych i wydajniejszych obliczeniowo.

% tutaj do dodania te prace, których jeszcze nie przeczytałem - na razie po prostu o structured
% training i o noisy student
\paragraph{Równolegle} do prac Korzeniowskiego i Widmera, jak również już po ich ostatnich
publikacjach związanych z tym tematem, powstawało wiele innych prac dotyczących zadania
rozpoznawania akordów muzycznych za pomocą sieci neuronowych. Wśród nich warto wspomnieć
\cite{mcfee_structured_2017}, gdzie autorzy próbują rozwiązać problem niezbalansowanych zbiorów
danych (w praktyce niektóre akordy występują znacznie rzadziej niż inne a do tego są bardzo podobne
do tych występujących częściej) poprzez "ustrukturyzowanie" treningu. Rozwiązanie to w uproszczeniu
polega na dołożeniu dodatkowych funkcji kosztu dla sieci neuronowej (dodatkowego nadzorowania),
wymuszających ekstrakcję pewnych konkretnych (wspólnych między akordami) cech. Wszystko to pozwala
osiągnąć trochę lepsze wyniki, jednakże wadą jest skomplikowanie rozwiązania. Ponadto sama idea i
kierunek badań mogą zostać poddane w wątpliwość, ze względu na dużą ingerencję w sposób działania
sieci neuronowej i wymuszanie pewnych zachowań. Alternatywą jest dążenie w kierunku generalizacji i
faktycznego polegania na danych uczących a nie na wiedzy dziedzinowej (tzw. podejście data driven).
Przykładem takiego kierunku badań są właśnie metody nienadzorowanego uczenia sieci neuronowych.
Bardzo dobrym przykładem jest \cite{bortolozzo_improving_2021}, gdzie autorzy aby rozwiązać
praktycznie ten sam problem niezbalansowania zbioru danych, wykorzystują dodatkowy zbiór danych
nieoznaczonych za pomocą odpowiednio zmodyfikowanego algorytmu \emph{Noisy Student}
\cite{xie_self-training_2020}. Problem wykorzystania dużej ilości danych nieoznaczonych i małej
ilości danych oznaczonych nazywa się uczeniem "pół-nadzorowanym" (ang. semi-supervised). Warto
wspomnieć, że istnieją inne, lepsze algorytmy pozwalające osiągnąć podobny efekt, wśród nich
\cite{pham_meta_2021} oraz \cite{chen_big_2020} są szczególnie warte uwagi. Tak więc
\cite{bortolozzo_improving_2021} jest zaledwie jednym z pierwszych podejść wykorzystania najnowszych
algorytmów typu semi-supervised i self-supervised w zadaniu rozpoznawania akordów.

% o transformerach
\paragraph{W} przetwarzaniu języka naturalnego już od kilku lat standardem jest architektura zwana
Transformerem \cite{vaswani_attention_2017}, która pozwala zrównoleglić obliczenia wcześniej
przeprowadzane sekwencyjne i w ogóle pozwala osiągnąć wyniki lepsze, niż stosowane wcześniej do tego
zadania sieci rekurencyjne. W ostatnim roku architektura ta weszła również do użytku w przetwarzaniu
obrazów \cite{dosovitskiy_image_2021} i obecnie modele tego typu osiągają wyniki lepsze niż
klasyczne splotowe sieci neuronowe. Jeszcze przed wprowadzeniem Transformerów do przetwarzania
obrazów wykonane zostały co najmniej dwie próby wykorzystania tej architektury do zadania
rozpoznawania akordów. Pierwsza z nich \cite{chen_harmony_2019} jest trudna do oceny ze względu na
małą liczę przeprowadzonych eksperymentów oraz brak realnego odniesienia do rozwiązań innych
autorów. Natomiast w \cite{park_bi-directional_2019} pokazane zostało, że Transformer może dać
wyniki bardzo zbliżone do osiąganych w \cite{korzeniowski_fully_2016}. Chociaż transformer nie
pozwolił osiągnąć lepszych wyników to należy pamiętać, że była to zaledwie pierwsza próba
wykorzystania tej architektury, która w najprostszej postaci sprawdziła się zupełnie zadowalająco.

Te pierwsze podejścia do wykorzystania Transformerów w zadaniu rozpoznawania akordów pozostawiają
bardzo duże pole do usprawnień. Przede wszystkim należy zwrócić uwagę na sposób, w jaki Transformery
zostały wprowadzone do przetwarzania obrazu \cite{dosovitskiy_image_2021} i spróbować przenieść
zastosowane tam rozwiązania do zadania rozpoznawania akordów. Ze względu na rosnącą popularność tej
architektury i liczne prace dotyczące proponowanych zmian i ulepszeń, nie brak inspiracji do
dalszych działań w tym obszarze. Należy zwrócić szczególną uwagę na to, że bardzo dużą zaletą
transformerów jest możliwość ich nienadzorowanego pretrenowania i późniejszego wykorzystania w
jakimś konkretnym zadaniu. W \cite{devlin_bert_2019} opisany został jeden z takich algorytmów
wykorzystywanych w przypadku NLP. Inne rodzaje sieci też mogą być oczywiście pretrenowane w sposób
nienadzorowany, ale Transformery okazują się bardziej niż inne rodzaje sieci zyskiwać na takim
treningu, co wykazano np. w \cite{caron_emerging_2021}.


\section{Analiza porównawcza z uwzględnieniem własnego rozwiązania}

Nienadzorowane uczenie sieci neuronowych jest stosowane już od kilku lat. Głównie miało to miejsce w
przypadku przetwarzania języka naturalnego, gdzie tworzenie tzw. language models jest właściwie
zadaniem nie wymagającym nadzoru (etykiet). Dodatkowo od dawna bardzo dużą popularności cieszą się
inne algorytmy, takie jak np. BERT \cite{devlin_bert_2019}. W przetwarzaniu obrazów algorytmy te
również wykorzystywane są już od dawna (np. \cite{noroozi_unsupervised_2017}), jednakże na początku
nie dawały one takich dobrych wyników i na popularności zaczęły zyskiwać dopiero w dwóch ostatnich
latach (\cite{chen_simple_2020}, \cite{xie_self-training_2020}). Łatwo więc zgadnąć, że tak jak
zadanie rozpoznawania akordów nie jest zbyt popularne w porównaniu do zadania klasyfiacji obrazów,
tak nie ma zbyt wielu prac dotyczących wykorzystania algorytmów uczenia nienadzorowanego w tej
dziedzinie. Jednakże można znaleźć pojedyncze prace dotycząceg tego tematu, lub tematu bardzo
pokrewnego. Poniżej wykonana zostanie analiza porównawcza rozwiązania autorskiego z rozwiązaniami z
literatury. Kryteria porównawcze są następujące:
\begin{itemize}
    \item Uzyskana poprawa dokładności klasyfikacji
    \item Skalowalność i generatywność
    \item Prostota rozwiązania i łatwość implementacji
\end{itemize}

Pierwszą porównywaną pracą jest \cite{wu_semi-supervised_2020}, która już w tytule ma jasno
zaznaczone, że dotyczy pół-nadzorowanego uczenia sieci neuronowych. Oznacza to więc, że autorzy
zdecydowali się wykorzystać dane nieoznaczone w celu usprawnienia jakości klasyfikacji. Właściwie
wykorzystują oni autoenkoder wariacyjny w celu wyuczenia sieci ekstrakcji odpowiednich cech. Jeżeli
chodzi o uzyskaną poprawę, to zaznaczają oni, że wykorzystanie zaproponowanego przez nich algorytmu
poprawia jakość klasyfikacji w stosunku do prostego uczenia nadzorowanego na tych samych danych.
Niestety nie porównują się do innych algorytmów. Pokazują natomiast wpływ proporcji danych
oznaczonych i nieoznaczonych na otrzymaną dokładność. W ramach autorskiej metody nie jest jeszcze
wiadomym, czy nastąpi jakakolwiek poprawa dokładności klasyfikacji. Co do skalowalności i
generatywności to omawiane rozwiązanie wydaje się być skalowalne na większe zbiory danych i
modyfikacje architektury. Rozwiązanie autorskie ma opierać się o wstępny trening typu
self-supervised na danych nieoznaczonych (np. algorytmem BYOL \cite{grill_bootstrap_2020}, DINO
\cite{caron_emerging_2021} lub podobnym) a następnie dotrenowanie sieci na danych oznaczonych,
zgodnie z procedurą opisaną w \cite{chen_big_2020}. Takie podejście również jest skalowalne ale
pozwala dobrać praktycznie dowolną architekturę sieci. Ponadto rozwiązanie autorskie zakłada
wytworzenie pretrenowanego modelu, potrafiącego ekstrachować istotne cechy, który może zostać
wykorzystany do dowolnego innego zadania, nie tylko do klasyfikacji akordów. Algorytm proponowany w
\cite{wu_semi-supervised_2020} jest przygotowany ściśle pod zadanie klasyfikacji akordów.
Implementacyjnie oba rozwiązania mogą nie być trywialne, natomiast rozwiązanie autorskie jest
bardziej modułowe i dzieli się poszczególne etapy, które dzieją się jeden po drugim, co pozwala na
większą elastyczność w wykonywaniu treningów.

Drugą istotną pracą, najbardziej zbliżoną do proponowanego, autorskiego rozwiązania, jest
\cite{bortolozzo_improving_2021}. Autorzy tego artykułu adaptują algorytm Noisy Student w celu
wykorzystania danych nieoznaczonych do poprawy jakości klasyfikacji akordów. Sam algorytm Noisy
Student jest algorytmem typu semi-supervised i właściwie z tego powodu rozwiązanie to jest bardziej
podobne do omawianego wcześniej \cite{wu_semi-supervised_2020} niż do rozwiązania autorskiego.
Jednakże z drugiej strony algorytm ten został zaadaptowany z dziedziny przetwarzania obrazów i w tym
sensie autorzy tej pracy zastosowali podejście takie jak w rozwiązaniu autorskim, które również
opiera się głównie o adaptację algorytmów z dziedziny przetwarzania obrazów. Jeżeli chodzi o
uzyskaną poprawność to wyniki autorów tego artykułu są bardzo spektakularne - wielokrotnie poprawia
się dokładność klasyfikacji rzadko występujących akordów. Jak już wspomniano wcześniej, wyniki
rozwiązania autorskiego na razie nie są znane, jednakże zakładany jest bardzo podobny efekt. Co do
skalowalności i generatywności, to wykorzystane w autorskim rozwiązaniu algorytmy są uniwersalne i
niezależne od problemu, bardzo podobnie jak algorytm Noisy Student. Jednakże koncepcja wstępnego
treningu self-supervised wciąż pozostaje bardziej uporządkowana i elastyczna niż algorytmy
semi-supervised. Łatwość implementacji pozostaje na zbliżonym poziomie, można nawet zaryzykować
stwierdzenie, że proponowany, autorski algorytm jest bardziej złożony.
